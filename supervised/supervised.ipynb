{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4702bc56-e33d-4ee0-b2df-6016de9cfec5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 4)\n",
    "\n",
    "df = pd.read_csv(\"books_bookvoed.csv\")\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11d3838-e4c6-4c5b-8354-e3f37d646caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "\n",
    "missing = df.isna().sum().sort_values(ascending=False)\n",
    "display(missing.to_frame(\"missing_count\"))\n",
    "\n",
    "display(df.describe(include=\"all\").T)\n",
    "\n",
    "summary = pd.DataFrame({\n",
    "    \"dtype\": df.dtypes.astype(str),\n",
    "    \"non_null\": df.notna().sum(),\n",
    "    \"missing\": df.isna().sum(),\n",
    "})\n",
    "display(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bdec08-73a1-4395-814b-828e05357ea4",
   "metadata": {},
   "source": [
    "При проверке обнаружилось, что пропусков нет и target статистически совпадает с price, \n",
    "значит при использовании price в признаках возникает утечка.\n",
    "В дальнейшем price исключаем из X при обучении модели на target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db909ec2-fd3b-44c4-b887-a6879f211716",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col, topn in [(\"publisher\", 20), (\"category\", None), (\"availability\", None)]:\n",
    "    if col not in df.columns:\n",
    "        continue\n",
    "\n",
    "    s = df[col].astype(\"string\")\n",
    "    vc = s.value_counts()\n",
    "\n",
    "    if topn is not None:\n",
    "        vc = vc.head(topn)\n",
    "\n",
    "    vc = vc.sort_values()\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    vc.plot(kind=\"barh\")\n",
    "    title = f\"{col} (top {topn})\" if topn else col\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"count\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "for col in [\"price\", \"old_price\", \"target\"]:\n",
    "    if col not in df.columns:\n",
    "        continue\n",
    "\n",
    "    s = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.hist(np.log1p(s), bins=60)\n",
    "    plt.title(f\"{col}\")\n",
    "    plt.xlabel(f\"{col}\")\n",
    "    plt.ylabel(\"count\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "if \"discount_percent\" in df.columns:\n",
    "    disc = df[\"discount_percent\"].astype(int)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 4))\n",
    "    ax.hist(disc, bins=range(disc.min(), disc.max() + 2))\n",
    "    ax.set_title(\"discount_percent\")\n",
    "    ax.set_xlabel(\"discount_percent\")\n",
    "    ax.set_ylabel(\"count\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "if {\"category\", \"price\"}.issubset(df.columns):\n",
    "    tmp = df[[\"category\", \"price\"]].copy()\n",
    "    tmp[\"price\"] = pd.to_numeric(tmp[\"price\"], errors=\"coerce\")\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 4))\n",
    "    tmp.boxplot(column=\"price\", by=\"category\", showfliers=False, rot=25, ax=ax);\n",
    "    plt.suptitle(\"\")\n",
    "    ax.set_title(\"price for category\")\n",
    "    ax.set_ylabel(\"price\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ad7652-0e04-4807-8bd9-ffee4e66250e",
   "metadata": {},
   "source": [
    "Распределения категориальных признаков неравномерны, есть доминирующие значения (особенно по category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0aa90a-2bc3-4252-a698-281911bc2765",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bad_old_lt_price = (df[\"old_price\"] < df[\"price\"]).sum()\n",
    "bad_disc_zero_but_diff = ((df[\"discount_percent\"] == 0) & (df[\"old_price\"] > df[\"price\"])).sum()\n",
    "bad_disc_pos_but_equal = ((df[\"discount_percent\"] > 0) & (df[\"old_price\"] == df[\"price\"])).sum()\n",
    "\n",
    "print(\"old_price < price:\", bad_old_lt_price)\n",
    "print(\"discount=0, но old_price>price:\", bad_disc_zero_but_diff)\n",
    "print(\"discount>0, но old_price==price:\", bad_disc_pos_but_equal)\n",
    "\n",
    "q = [0.5, 0.9, 0.95, 0.99, 0.995, 0.999]\n",
    "print(\"\\nprice quantiles:\\n\", df[\"price\"].quantile(q))\n",
    "print(\"\\nold_price quantiles:\\n\", df[\"old_price\"].quantile(q))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272e345d-97d9-4be4-af66-f794b58cfc18",
   "metadata": {},
   "source": [
    "Найдены неконсистентные строки (скидка 0 при old_price > price), требуется исправление"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a18675-358f-4d41-90b4-b24b22ee4241",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.copy()\n",
    "print(\"Всего пропусков в исходном df:\", int(df.isna().sum().sum()))\n",
    "print(\"Всего пропусков в df_clean:\", int(df_clean.isna().sum().sum()))\n",
    "\n",
    "mask = (df_clean[\"discount_percent\"] == 0) & (df_clean[\"old_price\"] > df_clean[\"price\"]) & (df_clean[\"old_price\"] > 0)\n",
    "\n",
    "print(\"Строк для исправления:\", int(mask.sum()))\n",
    "\n",
    "recalc = (1 - df_clean.loc[mask, \"price\"] / df_clean.loc[mask, \"old_price\"]) * 100\n",
    "df_clean.loc[mask, \"discount_percent\"] = np.ceil(recalc).astype(int)\n",
    "\n",
    "df_clean[\"discount_percent\"] = df_clean[\"discount_percent\"].clip(0, 90)\n",
    "\n",
    "check = ((df_clean[\"discount_percent\"] == 0) & (df_clean[\"old_price\"] > df_clean[\"price\"])).sum()\n",
    "print(\"После исправления осталось\", int(check))\n",
    "\n",
    "for col in [\"price\", \"old_price\", \"target\"]:\n",
    "    lo, hi = df_clean[col].quantile([0.001, 0.999])\n",
    "    df_clean[col] = df_clean[col].clip(lo, hi)\n",
    "\n",
    "num = df_clean[[\"price\", \"old_price\", \"discount_percent\", \"target\"]].copy()\n",
    "\n",
    "corr = num.corr(numeric_only=True)\n",
    "display(corr)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.imshow(corr, aspect=\"auto\")\n",
    "plt.xticks(range(len(corr.columns)), corr.columns, rotation=30, ha=\"right\")\n",
    "plt.yticks(range(len(corr.index)), corr.index)\n",
    "plt.colorbar()\n",
    "plt.title(\"Correlation (numeric features)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "df_clean[[\"price\", \"old_price\", \"discount_percent\", \"target\"]].describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efced9c-64f0-4b62-bc0b-75b391e30243",
   "metadata": {},
   "source": [
    "Еще одно подтверждение, что target статистически совпадает с price + данные приведены к консистентному виду"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4cc97c-aa9e-4857-83dc-21b48bd44b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = df_clean[\"title\"].astype(\"string\").fillna(\"\")\n",
    "\n",
    "df_clean[\"title_len\"] = t.str.len()\n",
    "df_clean[\"title_words\"] = t.str.split().str.len()\n",
    "df_clean[\"title_has_year\"] = t.str.contains(r\"\\b(?:19|20)\\d{2}\\b\", regex=True, na=False).astype(int)\n",
    "\n",
    "top_pub = df_clean[\"publisher\"].astype(\"string\").value_counts().head(30).index\n",
    "df_clean[\"publisher_top\"] = df_clean[\"publisher\"].astype(\"string\").where(df_clean[\"publisher\"].isin(top_pub), \"Other\")\n",
    "\n",
    "df_model = pd.get_dummies(\n",
    "    df_clean,\n",
    "    columns=[\"category\", \"availability\", \"publisher_top\"],\n",
    "    drop_first=False\n",
    ")\n",
    "\n",
    "X = df_model.drop(columns=[\"target\", \"title\", \"publisher\"])\n",
    "y = df_model[\"target\"]\n",
    "\n",
    "bool_cols = X.select_dtypes(include=\"bool\").columns\n",
    "X[bool_cols] = X[bool_cols].astype(int)\n",
    "\n",
    "print(\"X:\", X.shape, \"y:\", y.shape)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b772f8a-44b5-4e36-a4ad-c36899f68748",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "base_train, base_test = train_test_split(df_clean, test_size=0.2, random_state=42)\n",
    "\n",
    "y_train = base_train[\"target\"].to_numpy()\n",
    "y_test = base_test[\"target\"].to_numpy()\n",
    "\n",
    "pred1 = np.full(y_test.shape, np.median(y_train))\n",
    "mae1 = mean_absolute_error(y_test, pred1)\n",
    "rmse1 = np.sqrt(mean_squared_error(y_test, pred1))\n",
    "r2_1 = r2_score(y_test, pred1)\n",
    "\n",
    "print(f\"Median: MAE={mae1:.3f}, RMSE={rmse1:.3f}, R2={r2_1:.3f}\")\n",
    "\n",
    "cat_median = base_train.groupby(\"category\")[\"target\"].median()\n",
    "global_median = base_train[\"target\"].median()\n",
    "\n",
    "pred2 = base_test[\"category\"].map(cat_median).fillna(global_median).to_numpy()\n",
    "mae2 = mean_absolute_error(y_test, pred2)\n",
    "rmse2 = np.sqrt(mean_squared_error(y_test, pred2))\n",
    "r2_2 = r2_score(y_test, pred2)\n",
    "\n",
    "print(f\"By category: MAE={mae2:.3f}, RMSE={rmse2:.3f}, R2={r2_2:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115a400a-0e9c-4c8c-9b13-52ab1f3972fe",
   "metadata": {},
   "source": [
    "Baseline даёт MAE +- равный 515 и R2<0, значит простые правила/if-else работают плохо и модель должна улучшить результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde955b5-a999-4157-967b-6b9feb717279",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = [\"old_price\", \"discount_percent\", \"title_len\", \"title_words\", \"title_has_year\"]\n",
    "cat_cols = [\"category\", \"availability\", \"publisher_top\"]\n",
    "\n",
    "X = df_clean[num_cols + cat_cols].copy()\n",
    "y = df_clean[\"target\"].copy()\n",
    "\n",
    "y_bins = pd.qcut(y, q=10, duplicates=\"drop\")\n",
    "\n",
    "X_tmp, X_test, y_tmp, y_test, bins_tmp, _ = train_test_split(\n",
    "    X, y, y_bins,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_bins\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_tmp, y_tmp,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=bins_tmp\n",
    ")\n",
    "\n",
    "print(\"train:\", X_train.shape, \"val:\", X_val.shape, \"test:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d93021-a12d-47b7-9aac-38f39bfdb2df",
   "metadata": {},
   "source": [
    "Я использую разбиение таргета на квантили и стратифицирую по этим бинам, чтобы распределение target было сопоставимым во всех частях.\n",
    "В данных нет временного признака, поэтому time-based split применить нельзя значит используем случайный split с фиксированным random_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5c83c4-1ab6-46b8-a421-8d19751d9636",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "for c in num_cols:\n",
    "    X_train[c] = pd.to_numeric(X_train[c], errors=\"coerce\")\n",
    "    X_val[c]   = pd.to_numeric(X_val[c], errors=\"coerce\")\n",
    "    X_test[c]  = pd.to_numeric(X_test[c], errors=\"coerce\")\n",
    "\n",
    "def metrics(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return mae, rmse, r2\n",
    "\n",
    "prep = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
    "        (\"num\", \"passthrough\", num_cols),\n",
    "    ]\n",
    ")\n",
    "\n",
    "variants = [True, False]\n",
    "rows = []\n",
    "best_fit_intercept = None\n",
    "best_mae = float(\"inf\")\n",
    "\n",
    "for fit_intercept in variants:\n",
    "    pipe = Pipeline([\n",
    "        (\"prep\", prep),\n",
    "        (\"lr\", LinearRegression(fit_intercept=fit_intercept)),\n",
    "    ])\n",
    "\n",
    "    pipe.fit(X_train, y_train)\n",
    "    pred_val = pipe.predict(X_val)\n",
    "\n",
    "    mae, rmse, r2 = metrics(y_val, pred_val)\n",
    "    rows.append({\n",
    "        \"fit_intercept\": fit_intercept,\n",
    "        \"MAE_val\": mae,\n",
    "        \"RMSE_val\": rmse,\n",
    "        \"R2_val\": r2\n",
    "    })\n",
    "\n",
    "    if mae < best_mae:\n",
    "        best_mae = mae\n",
    "        best_fit_intercept = fit_intercept\n",
    "\n",
    "results = pd.DataFrame(rows).sort_values(\"MAE_val\")\n",
    "display(results)\n",
    "print({\"fit_intercept\": best_fit_intercept})\n",
    "best_params = {\"fit_intercept\": best_fit_intercept}\n",
    "\n",
    "X_train_full = pd.concat([X_train, X_val], axis=0)\n",
    "y_train_full = pd.concat([y_train, y_val], axis=0)\n",
    "\n",
    "final_pipe = Pipeline([\n",
    "    (\"prep\", prep),\n",
    "    (\"lr\", LinearRegression(fit_intercept=best_fit_intercept)),\n",
    "])\n",
    "\n",
    "final_pipe.fit(X_train_full, y_train_full)\n",
    "pred_test = final_pipe.predict(X_test)\n",
    "\n",
    "mae_t, rmse_t, r2_t = metrics(y_test, pred_test)\n",
    "print(f\"MAE={mae_t:.3f}, RMSE={rmse_t:.3f}, R2={r2_t:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154a7c39-ef19-49cb-8d58-6d014b56f18b",
   "metadata": {},
   "source": [
    "Категориальные признаки кодируются через OneHotEncoder (не ломается на новых категориях благодаря handle_unknown=\"ignore\"), числовые передаются как есть. Гиперпараметр подбираю вручную перебором fit_intercept {True, False} по MAE на валидации, затем обучаю финальную модель на объединённых train+val и оцениваю качество на test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eaee471-08eb-49f9-9793-bc7bd1357496",
   "metadata": {},
   "source": [
    "Метрики на test близки к val соответственно явного переобучения не наблюдается.\n",
    "Качество сильно лучше baseline, значит модель реально учится на признаках"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07367590-fec3-4e65-b547-1525be5ecd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "prep = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
    "        (\"num\", \"passthrough\", num_cols),\n",
    "    ],\n",
    ")\n",
    "\n",
    "lin_pipe = Pipeline([\n",
    "    (\"prep\", prep),\n",
    "    (\"lr\", LinearRegression(**best_params)),\n",
    "])\n",
    "\n",
    "lin_pipe.fit(X_train, y_train)\n",
    "\n",
    "pred_train = lin_pipe.predict(X_train)\n",
    "pred_val   = lin_pipe.predict(X_val)\n",
    "pred_test  = lin_pipe.predict(X_test)\n",
    "\n",
    "rows = []\n",
    "for split, yt, yp in [\n",
    "    (\"train\", y_train, pred_train),\n",
    "    (\"val\",   y_val,   pred_val),\n",
    "    (\"test\",  y_test,  pred_test),\n",
    "]:\n",
    "    rows.append({\n",
    "        \"split\": split,\n",
    "        \"MAE\":  mean_absolute_error(yt, yp),\n",
    "        \"RMSE\": np.sqrt(mean_squared_error(yt, yp)),\n",
    "        \"R2\":   r2_score(yt, yp),\n",
    "    })\n",
    "\n",
    "report = pd.DataFrame(rows).set_index(\"split\").round(4)\n",
    "display(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b869b83d-f023-48eb-909e-f75679a1ce64",
   "metadata": {},
   "source": [
    "Метрики на train/val/test очень близки, поэтому переобучения нет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66573ac-6078-4f09-9959-b59b6000b0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "prep_sgd = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
    "        (\"num\", StandardScaler(with_mean=False), num_cols),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    ")\n",
    "\n",
    "sgd = SGDRegressor(\n",
    "    loss=\"squared_error\",\n",
    "    penalty=None,\n",
    "    max_iter=1,\n",
    "    warm_start=True,\n",
    "    tol=None,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "sgd_pipe = Pipeline([(\"prep\", prep_sgd), (\"model\", sgd)])\n",
    "\n",
    "epochs = 15\n",
    "hist = []\n",
    "\n",
    "best_val = float(\"inf\")\n",
    "bad_steps = 0\n",
    "\n",
    "for ep in range(1, epochs + 1):\n",
    "    sgd_pipe.fit(X_train, y_train)\n",
    "\n",
    "    tr_pred = sgd_pipe.predict(X_train)\n",
    "    va_pred = sgd_pipe.predict(X_val)\n",
    "\n",
    "    tr_mae = mean_absolute_error(y_train, tr_pred)\n",
    "    va_mae = mean_absolute_error(y_val, va_pred)\n",
    "\n",
    "    tr_rmse = np.sqrt(mean_squared_error(y_train, tr_pred))\n",
    "    va_rmse = np.sqrt(mean_squared_error(y_val, va_pred))\n",
    "\n",
    "    hist.append((ep, tr_mae, va_mae, tr_rmse, va_rmse))\n",
    "\n",
    "    if va_mae < best_val - 1e-4:\n",
    "        best_val = va_mae\n",
    "        bad_steps = 0\n",
    "    else:\n",
    "        bad_steps += 1\n",
    "        if bad_steps >= 5:\n",
    "            break\n",
    "\n",
    "hist = pd.DataFrame(hist, columns=[\"epoch\", \"mae_train\", \"mae_val\", \"rmse_train\", \"rmse_val\"])\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(hist[\"epoch\"], hist[\"mae_train\"], label=\"train\")\n",
    "plt.plot(hist[\"epoch\"], hist[\"mae_val\"], label=\"val\")\n",
    "plt.title(\"MAE по эпохам\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"MAE\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(hist[\"epoch\"], hist[\"rmse_train\"], label=\"train\")\n",
    "plt.plot(hist[\"epoch\"], hist[\"rmse_val\"], label=\"val\")\n",
    "plt.title(\"RMSE по эпохам\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e239fac-273f-4f1e-899c-d15b815c6730",
   "metadata": {},
   "source": [
    "SGDRegressor - линейная регрессия + градиентный спуск, то есть есть эпохи, в отличии от простой линейной регрессии\n",
    "в пункте просят работу с эпохами, так что я работаю с данным видом линейной регресии"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f4e7dd-3138-4855-a50e-e81439377fc0",
   "metadata": {},
   "source": [
    "При max_iter=1 и warm_start=True каждый вызов fit() добавляет одну итерацию оптимизации, поэтому можно наблюдать снижение MAE/RMSE на train и val.\n",
    "По графикам видно быстрое улучшение на первых шагах, разрыв между train и val небольшой и не растёт, переобучения нет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce271149-0c76-4c53-89ab-29ae8740fa15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "prep_gd = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
    "        (\"num\", StandardScaler(with_mean=False), num_cols),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    ")\n",
    "\n",
    "Xtr = prep_gd.fit_transform(X_train)\n",
    "Xva = prep_gd.transform(X_val)\n",
    "Xte = prep_gd.transform(X_test)\n",
    "\n",
    "ytr = y_train.to_numpy(dtype=float)\n",
    "yva = y_val.to_numpy(dtype=float)\n",
    "yte = y_test.to_numpy(dtype=float)\n",
    "\n",
    "\n",
    "def calc_metrics(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return mae, rmse, r2\n",
    "\n",
    "\n",
    "class LinearRegressionGD:\n",
    "    def __init__(self, lr=0.01, epochs=50, l2=0.0, fit_intercept=True, random_state=42):\n",
    "        self.lr = float(lr)\n",
    "        self.epochs = int(epochs)\n",
    "        self.l2 = float(l2)\n",
    "        self.fit_intercept = bool(fit_intercept)\n",
    "        self.random_state = int(random_state)\n",
    "\n",
    "        self.w_ = None\n",
    "        self.b_ = 0.0\n",
    "\n",
    "    def fit(self, X, y, X_val=None, y_val=None, track=False):\n",
    "        n, d = X.shape\n",
    "\n",
    "        rng = np.random.RandomState(self.random_state)\n",
    "        self.w_ = rng.normal(scale=0.01, size=d)\n",
    "        self.b_ = 0.0\n",
    "\n",
    "        history = {\"epoch\": [], \"mae_train\": [], \"mae_val\": []} if track else None\n",
    "\n",
    "        for ep in range(1, self.epochs + 1):\n",
    "            pred = X.dot(self.w_)\n",
    "            if self.fit_intercept:\n",
    "                pred = pred + self.b_\n",
    "\n",
    "            err = pred - y\n",
    "\n",
    "            grad_w = (X.T.dot(err)) / n\n",
    "            if self.l2:\n",
    "                grad_w = grad_w + self.l2 * self.w_\n",
    "\n",
    "            self.w_ -= self.lr * grad_w\n",
    "\n",
    "            if self.fit_intercept:\n",
    "                self.b_ -= self.lr * err.mean()\n",
    "\n",
    "            if track and X_val is not None and y_val is not None:\n",
    "                tr_pred = self.predict(X)\n",
    "                va_pred = self.predict(X_val)\n",
    "                history[\"epoch\"].append(ep)\n",
    "                history[\"mae_train\"].append(mean_absolute_error(y, tr_pred))\n",
    "                history[\"mae_val\"].append(mean_absolute_error(y_val, va_pred))\n",
    "\n",
    "        return history\n",
    "\n",
    "    def predict(self, X):\n",
    "        pred = X.dot(self.w_)\n",
    "        if self.fit_intercept:\n",
    "            pred = pred + self.b_\n",
    "        return pred\n",
    "\n",
    "grid = []\n",
    "for lr in [0.005, 0.01, 0.03]:\n",
    "    for l2 in [0.0, 1e-4, 1e-3]:\n",
    "        for fi in [True, False]:\n",
    "            grid.append({\"lr\": lr, \"epochs\": 60, \"l2\": l2, \"fit_intercept\": fi})\n",
    "\n",
    "rows = []\n",
    "best_params = None\n",
    "best_mae = float(\"inf\")\n",
    "\n",
    "for params in grid:\n",
    "    m = LinearRegressionGD(**params)\n",
    "    m.fit(Xtr, ytr)\n",
    "\n",
    "    val_pred = m.predict(Xva)\n",
    "    if not np.isfinite(val_pred).all():\n",
    "        continue\n",
    "\n",
    "    mae, rmse, r2 = calc_metrics(yva, val_pred)\n",
    "    rows.append({**params, \"MAE_val\": mae, \"RMSE_val\": rmse, \"R2_val\": r2})\n",
    "\n",
    "    if mae < best_mae:\n",
    "        best_mae = mae\n",
    "        best_params = params\n",
    "\n",
    "results = pd.DataFrame(rows).sort_values(\"MAE_val\").reset_index(drop=True)\n",
    "display(results.head(10))\n",
    "print(best_params)\n",
    "\n",
    "curve_model = LinearRegressionGD(**best_params)\n",
    "hist = curve_model.fit(Xtr, ytr, X_val=Xva, y_val=yva, track=True)\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(hist[\"epoch\"], hist[\"mae_train\"], label=\"train\")\n",
    "plt.plot(hist[\"epoch\"], hist[\"mae_val\"], label=\"val\")\n",
    "plt.title(\"MAE по эпохам\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"MAE\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "Xfull = sparse.vstack([Xtr, Xva], format=\"csr\")\n",
    "yfull = np.concatenate([ytr, yva])\n",
    "\n",
    "final_model = LinearRegressionGD(**best_params)\n",
    "final_model.fit(Xfull, yfull)\n",
    "\n",
    "test_pred = final_model.predict(Xte)\n",
    "mae_te, rmse_te, r2_te = calc_metrics(yte, test_pred)\n",
    "print(f\"MAE={mae_te:.3f}, RMSE={rmse_te:.3f}, R2={r2_te:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4643be73-6a01-4611-9e69-d65262cb5a9b",
   "metadata": {},
   "source": [
    "График MAE по эпохам показывает стабильное уменьшение ошибки и близость train/val, то есть переобучения нет\n",
    "Финальная модель обучена на объединении train+val и оценена на test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b1bf73-1e98-434c-81ec-434f1f199bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import clone\n",
    "\n",
    "def reg_metrics(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true, dtype=float).ravel()\n",
    "    y_pred = np.asarray(y_pred, dtype=float).ravel()\n",
    "\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return mae, rmse, r2\n",
    "\n",
    "prep_tpl = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
    "        (\"num\", StandardScaler(with_mean=False), num_cols),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    ")\n",
    "\n",
    "prep_lr = clone(prep_tpl)\n",
    "sk = Pipeline([\n",
    "    (\"prep\", prep_lr),\n",
    "    (\"model\", LinearRegression(fit_intercept=True)),\n",
    "])\n",
    "sk.fit(X_train, y_train)\n",
    "\n",
    "sk_val = reg_metrics(y_val, sk.predict(X_val))\n",
    "sk_test = reg_metrics(y_test, sk.predict(X_test))\n",
    "\n",
    "prep_gd = clone(prep_tpl)\n",
    "Xtr = prep_gd.fit_transform(X_train)\n",
    "Xva = prep_gd.transform(X_val)\n",
    "Xte = prep_gd.transform(X_test)\n",
    "\n",
    "ytr = np.asarray(y_train, dtype=float).ravel()\n",
    "yva = np.asarray(y_val, dtype=float).ravel()\n",
    "yte = np.asarray(y_test, dtype=float).ravel()\n",
    "\n",
    "gd = LinearRegressionGD(lr=0.003, epochs=4000, l2=0.0, fit_intercept=True, random_state=42)\n",
    "gd.fit(Xtr, ytr)\n",
    "\n",
    "gd_val = reg_metrics(yva, gd.predict(Xva))\n",
    "gd_test = reg_metrics(yte, gd.predict(Xte))\n",
    "\n",
    "cmp = pd.DataFrame([\n",
    "    {\"model\": \"sklearn LinearRegression\", \"split\": \"val\",  \"MAE\": sk_val[0],  \"RMSE\": sk_val[1],  \"R2\": sk_val[2]},\n",
    "    {\"model\": \"sklearn LinearRegression\", \"split\": \"test\", \"MAE\": sk_test[0], \"RMSE\": sk_test[1], \"R2\": sk_test[2]},\n",
    "    {\"model\": \"my LinearRegressionGD\",    \"split\": \"val\",  \"MAE\": gd_val[0],  \"RMSE\": gd_val[1],  \"R2\": gd_val[2]},\n",
    "    {\"model\": \"my LinearRegressionGD\",    \"split\": \"test\", \"MAE\": gd_test[0], \"RMSE\": gd_test[1], \"R2\": gd_test[2]},\n",
    "]).round(4)\n",
    "\n",
    "display(cmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fb38c2-e61d-4c9f-9474-a7fc4e6e3ae5",
   "metadata": {},
   "source": [
    "Разница метрик ожидаема, так как sklearn решает задачу в закрытой форме, а GD итерационно и чувствителен к lr/epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c397c948-ba40-4e27-bdab-2e768acc055d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = [\n",
    "    (0.004, 1500),\n",
    "    (0.003, 2000),\n",
    "    (0.003, 4000),\n",
    "    (0.002, 6000),\n",
    "    (0.0015, 8000),\n",
    "]\n",
    "\n",
    "rows = []\n",
    "for lr, epochs in trials:\n",
    "    m = LinearRegressionGD(lr=lr, epochs=epochs, l2=0.0, fit_intercept=True, random_state=42)\n",
    "    m.fit(Xtr, ytr)\n",
    "\n",
    "    pred = m.predict(Xva)\n",
    "    if not np.isfinite(pred).all():\n",
    "        rows.append({\"lr\": lr, \"epochs\": epochs, \"MAE_val\": np.nan, \"RMSE_val\": np.nan, \"R2_val\": np.nan})\n",
    "        continue\n",
    "\n",
    "    mae, rmse, r2 = reg_metrics(yva, pred)\n",
    "    rows.append({\"lr\": lr, \"epochs\": epochs, \"MAE_val\": mae, \"RMSE_val\": rmse, \"R2_val\": r2})\n",
    "\n",
    "probe = pd.DataFrame(rows).round(4).sort_values(\"MAE_val\")\n",
    "display(probe)\n",
    "\n",
    "print(\"sklearn val:\",\n",
    "      {\"MAE\": round(float(sk_val[0]), 4),\n",
    "       \"RMSE\": round(float(sk_val[1]), 4),\n",
    "       \"R2\": round(float(sk_val[2]), 4)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b91db6c-9703-48b2-97d5-42d8654d4655",
   "metadata": {},
   "source": [
    "Видно, что при подборе lr/epochs качество приближается к sklearn, а не “улетает” в inf/NaN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
